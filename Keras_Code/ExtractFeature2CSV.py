from __future__ import print_function
import keras
import sys
from keras.datasets import mnist

from keras.models import Sequential

from keras.layers import Input, Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D

from keras import backend as K

import numpy as np  
import os
import time
np.random.seed(1337)  
from keras.utils import np_utils  
from keras.models import Model

#DNN setting
batch_size = 64
num_classes = 2
epochs = 10
#input image dimensions
img_rows, img_cols = 42, 27



###############################################################################
#If equall to 'yes', then load from Bin file
FAST_LOAD = 'yes1'
#postfix
FILE_TYPE = '1134d_all'

#Feature column
COLUMN = 1134
#K-Fold
K = 10
k = 1
if len(sys.argv)>=2:
	k = int(sys.argv[1])
if len(sys.argv)>=3:
	K = int(sys.argv[2])	

	
#Log setting
LOG_FLAG = 1
log_str = ''
logfilename = '../log/'+os.path.basename(sys.argv[0])+'_'+str(K)+'_'+str(k)+'.txt'
log_str = log_str + 'Start: '+time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))+'\r\n'


bot_file = sys.argv[3]#'../data/botnet_norm'+'_'+FILE_TYPE+'.txt'
back_file = sys.argv[4]#'../data/background_norm'+'_'+FILE_TYPE+'.txt'
bin_file = '../data/sample'+'_'+FILE_TYPE+'.bin'


sample = []
if FAST_LOAD=='yes':
	sample = np.fromfile(bin_file, dtype=np.double)
	sample = sample.reshape(-1, COLUMN+1)
else:
	bot_orig = (np.loadtxt(bot_file, dtype=np.str, delimiter="\t"))[:,2:].astype(np.double)
	label = np.ones((len(bot_orig),1))
	bot_orig = np.hstack((bot_orig,label))
	
	back_orig = (np.loadtxt(back_file, dtype=np.str, delimiter="\t"))[:,2:].astype(np.double)
	label = np.zeros((len(back_orig),1))
	back_orig = np.hstack((back_orig,label))
	
	sample = np.vstack((bot_orig, back_orig))
	np.random.shuffle(sample)
	sample.tofile(bin_file)

	
gridLen = int(len(sample)*1.0/K)
s_index = (k-1)*gridLen
e_index = k*gridLen

testX = sample[s_index:e_index, :-1]
testY = sample[s_index:e_index, -1]

if k==1:
	trainX = sample[e_index:, :-1]
	trainY = sample[e_index:, -1]
elif k==K:
	trainX = sample[0:s_index, :-1]
	trainY = sample[0:s_index, -1]
else:	
	trainX = np.vstack((sample[0:s_index, :-1], sample[e_index:, :-1]))
	trainY = np.hstack((sample[0:s_index, -1], sample[e_index:, -1]))

trainYBackup = trainY
testYBackup = testY

print ('Train Size:'+str(len(trainY)))
print ('Test Size:'+str(len(testY)))
###############################################################################

#save loss acc
class LossHistory(keras.callbacks.Callback):
	def on_train_begin(self, logs={}):
		self.losses = {'batch':[], 'epoch':[]}
		self.accuracy = {'batch':[], 'epoch':[]}
		self.val_loss = {'batch':[], 'epoch':[]}
		self.val_acc = {'batch':[], 'epoch':[]}

	def on_batch_end(self, batch, logs={}):
		self.losses['batch'].append(logs.get('loss'))
		self.accuracy['batch'].append(logs.get('acc'))
		self.val_loss['batch'].append(logs.get('val_loss'))
		self.val_acc['batch'].append(logs.get('val_acc'))

	def on_epoch_end(self, batch, logs={}):
		self.losses['epoch'].append(logs.get('loss'))
		self.accuracy['epoch'].append(logs.get('acc'))
		self.val_loss['epoch'].append(logs.get('val_loss'))
		self.val_acc['epoch'].append(logs.get('val_acc'))

	def getHistory(self):
		epoch_losses_str = ','.join(str(i) for i in self.losses['epoch'])
		epoch_accuracy_str = ','.join(str(i) for i in self.accuracy['epoch'])
		epoch_val_loss_str = ','.join(str(i) for i in self.val_loss['epoch'])
		epoch_val_acc_str = ','.join(str(i) for i in self.val_acc['epoch'])
		
		batch_losses_str = ','.join(str(i) for i in self.losses['batch'])
		batch_accuracy_str = ','.join(str(i) for i in self.accuracy['batch'])
		#batch_val_loss_str = ','.join(str(i) for i in self.val_loss['batch'])
		#batch_val_acc_str = ','.join(str(i) for i in self.val_acc['batch'])
		
		rt_str = ''
		rt_str = rt_str + 'epoch_losses:' + epoch_losses_str + '\r\n'
		rt_str = rt_str + 'epoch_accuracy:' + epoch_accuracy_str + '\r\n'
		rt_str = rt_str + 'epoch_val_loss:' + epoch_val_loss_str + '\r\n'
		rt_str = rt_str + 'epoch_val_acc:' + epoch_val_acc_str + '\r\n'
		
		rt_str = rt_str + 'batch_losses:' + batch_losses_str + '\r\n'
		rt_str = rt_str + 'batch_accuracy:' + batch_accuracy_str + '\r\n'
		#rt_str = rt_str + 'batch_val_loss:' + batch_val_loss_str + '\r\n'
		#rt_str = rt_str + 'batch_val_acc:' + batch_val_acc_str + '\r\n'
		
		return rt_str
		
###############################################################################
history = LossHistory()
	
	
trainX = trainX.reshape(-1, img_rows, img_cols, 1)
testX = testX.reshape(-1, img_rows, img_cols, 1)

trainY=np_utils.to_categorical(trainY, num_classes)
testY=np_utils.to_categorical(testY, num_classes)

input_shape = (img_rows, img_cols, 1)


print('trainX shape:', trainX.shape)
print(trainX.shape[0], 'train samples')
print(testX.shape[0], 'test samples')


input_data = Input(shape=input_shape)
conv = Conv2D(32, kernel_size=(2, 2), activation='tanh')(input_data)
conv = Conv2D(64, (2, 2), activation='tanh')(conv)
conv = MaxPooling2D(pool_size=(2, 2))(conv)
conv = Dropout(0.2)(conv)
conv = Flatten()(conv)
conv_output = Dense(128, activation='tanh')(conv)
full = Dropout(0.2)(conv_output)
full_output = Dense(num_classes, activation='softmax')(full)

model = Model(inputs=input_data, outputs=full_output)
featureEx_model = Model(inputs=input_data, outputs=conv_output)


model.compile(loss=keras.losses.categorical_crossentropy,
			  optimizer=keras.optimizers.Adadelta(),
			  metrics=['accuracy'])

model.fit(trainX, trainY,
		  batch_size=batch_size,
		  epochs=epochs,
		  verbose=1,
		  validation_data=(testX, testY),
		  callbacks=[history])


score = model.evaluate(testX, testY, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

#print (history.getHistory())


model.save(os.path.basename(sys.argv[0])+'_model'+'_'+FILE_TYPE+'.h5')
featureEx_model.save(os.path.basename(sys.argv[0])+'_fex_model'+'_'+FILE_TYPE+'.h5')


test_rst = model.predict(testX)
#np.savetxt('rst2.csv', rst, delimiter = ',')


test_label = {}
for i in range(0, len(test_rst)):
	if test_rst[i][0]<test_rst[i][1]:
		test_label[i] = 1
	else:
		test_label[i] = 0
testY=testYBackup

tp = 0
fn = 0
fp = 0
tn = 0



for i in range(0, len(test_label)):
	if testY[i]==1:
		if testY[i]==test_label[i]:
			tp = tp+1
		else:
			fn = fn+1
	else:
		if testY[i]==test_label[i]:
			tn = tn+1
		else:
			fp = fp+1
			
accuracy = (tp+tn)*1.0/(tp+tn+fn+fp)
percise = tp*1.0/(tp+fp)
recall = tp*1.0/(tp+fn)

print('\naccuracy:'+str(accuracy))
print('percise:'+str(percise))
print('recall:'+str(recall))

trainYBackup = trainYBackup.reshape(-1, 1)
testYBackup = testYBackup.reshape(-1, 1)

features = featureEx_model.predict(testX)
features2 = featureEx_model.predict(trainX)
all_sampleX = np.vstack((features, features2))
all_sampleY = np.vstack((testYBackup, trainYBackup))


np.savetxt('CNN_featuresX.csv', all_sampleX, delimiter = ',')
np.savetxt('CNN_featuresY.csv', all_sampleY, delimiter = '\r\n')
